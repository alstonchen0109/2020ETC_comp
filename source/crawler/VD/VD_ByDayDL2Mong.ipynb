{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@vdid_1_@datacollecttime_1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "import xmltodict\n",
    "import os\n",
    "import pandas as pd\n",
    "import io\n",
    "import datetime\n",
    "import pymongo\n",
    "import json\n",
    "import gzip\n",
    "import dns\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "urlBase='https://tisvcloud.freeway.gov.tw/history/vd/'  # 20190624/cms_value_0000.xml.gz   20190624/cms_value_0014.xml.gz\n",
    "baseDir='../../../data/'\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client.traffic\n",
    "trType='vd'\n",
    "#建立 unique index 以防重複 insert doc to mongodb, 並且加速查詢, 如果同樣的 compound unique index已經存在則不作用\n",
    "db['vd1'].create_index([(\"@vdid\",1),(\"@datacollecttime\",1)],unique=True)\n",
    "db['vd5'].create_index([(\"@vdid\",1),(\"@datacollecttime\",1)],unique=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#確認該 url 是否可以下載, 例如 20190230 就不存在, 無法下載; 而且必須是附件形式的方可\n",
    "def isDownloadable(url):\n",
    "    \"\"\"\n",
    "    Does the url contain a downloadable resource\n",
    "    \"\"\"\n",
    "    h = requests.head(url, allow_redirects=True)\n",
    "    header = h.headers\n",
    "    content_type = header.get('content-type')\n",
    "    if content_type is None:\n",
    "        return False\n",
    "    if 'text' in content_type.lower():\n",
    "        return False\n",
    "    if 'html' in content_type.lower():\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下載某url檔案後, 放在指定目錄下\n",
    "def downloadFileFromUrl(url, directory):\n",
    "    filename = directory+'/'+ url.rsplit('/', 1)[1]\n",
    "    if not os.path.exists(filename):\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(filename, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抓取 CMS 的某一天每1分鐘一次 所有檔案 並下載到指定目錄\n",
    "def downloadVD1MinDay(trType, day, baseDir):\n",
    "    downloads=[]\n",
    "    for hour in range(0,24):\n",
    "        for mininute in range(0,60,1):  #vd 每5分鐘一次\n",
    "            downloads.append(urlBase + day + '/' + trType + '_value_'+ format(hour, '02d')+ format(mininute, '02d') +'.xml.gz' )\n",
    "    p=baseDir+trType+'1Min'+'/'+day\n",
    "    Path(p).mkdir(parents=True, exist_ok=True)\n",
    "    for url in downloads:\n",
    "        if isDownloadable(url):\n",
    "            downloadFileFromUrl(url,p)\n",
    "            #print(url)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抓取 CMS 的某一天每5分鐘一次 所有檔案 並下載到指定目錄\n",
    "def downloadVD5MinDay(trType, day, baseDir):\n",
    "    downloads=[]\n",
    "    for hour in range(0,24):\n",
    "        for mininute in range(0,60,5):  #vd 每5分鐘一次\n",
    "            downloads.append(urlBase + day + '/' + trType + '_value5_'+ format(hour, '02d')+ format(mininute, '02d') +'.xml.gz' )\n",
    "    p=baseDir+trType+'/'+day\n",
    "    Path(p).mkdir(parents=True, exist_ok=True)\n",
    "    for url in downloads:\n",
    "        if isDownloadable(url):\n",
    "            downloadFileFromUrl(url,p)\n",
    "            #print(url)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertFiles2Mongo(files, directory, OneMinute=True):\n",
    "    if OneMinute:\n",
    "        collect=db['vd1']\n",
    "    else:    \n",
    "        collect=db['vd5']\n",
    "    i=1\n",
    "    for file in files:\n",
    "        print(i,directory,file)\n",
    "        i += 1\n",
    "        f = gzip.open(directory+file, 'rb')\n",
    "        doc = xmltodict.parse(f)\n",
    "        Y=doc['XML_Head']['Infos']\n",
    "        if Y is not None:\n",
    "            X=Y['Info']\n",
    "            #has datacollecttime, no need updateTime=datetime.datetime.strptime(doc['XML_Head']['@updatetime'], \"%Y/%m/%d %H:%M:%S\")\n",
    "            json_data = json.dumps(X)\n",
    "            cc = json.loads(json_data)\n",
    "            tmpDF=pd.DataFrame(cc)\n",
    "            tmpDF['@datacollecttime']=tmpDF['@datacollecttime'].apply(lambda x:datetime.datetime.strptime(x, \"%Y/%m/%d %H:%M:%S\"))\n",
    "            tmpDF['lane']=tmpDF['lane'].apply(splitLane2DF)\n",
    "            #print(tmpDF['lane'][0],'\\n',tmpDF['lane'][1],'\\n',tmpDF['lane'][2],'\\n',tmpDF['lane'][3])\n",
    "            #a=cc[1]\n",
    "            #print(a['@vdid'],a['@datacollecttime'],a['@status'],'\\n',splitLane2DF(a['lane'])) \n",
    "            records = tmpDF.to_dict('records')\n",
    "            try:\n",
    "                collect.insert_many(records)\n",
    "            except Exception as err:\n",
    "                print (\"collect.insert_many ERROR:\", err)    \n",
    "        else:\n",
    "            print('TypeError: ',Y)\n",
    "        \n",
    "        f.close()\n",
    "        ######3##########TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "def downnload1HourFiles2Mongo(trType, day, hour, baseDir, OneMinute=True):\n",
    "    downloads=[]\n",
    "    p=baseDir+trType+'1Min'+'/'+day+'/'\n",
    "    if OneMinute:\n",
    "        for mininute in range(0,60,1):  #vd 每1分鐘一次\n",
    "            downloads.append(urlBase + day + '/' + trType + '_value_'+ format(hour, '02d')+ format(mininute, '02d') +'.xml.gz' )\n",
    "        Path(p).mkdir(parents=True, exist_ok=True)\n",
    "    else:\n",
    "        for mininute in range(0,60,5):  #vd 每1分鐘一次\n",
    "            downloads.append(urlBase + day + '/' + trType + '_value5_'+ format(hour, '02d')+ format(mininute, '02d') +'.xml.gz' )\n",
    "        p=baseDir+trType+'5Min'+'/'+day+'/'\n",
    "        Path(p).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for url in downloads:\n",
    "        if isDownloadable(url):\n",
    "            downloadFileFromUrl(url,p)\n",
    "            \n",
    "            insertFiles2Mongo([os.path.basename(urlparse(url).path)], p, True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ../../../data/vd1Min/20190322/ vd_value_1900.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1901.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1902.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1903.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1904.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1905.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1906.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1907.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1908.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1909.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1910.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1911.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1912.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1913.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1914.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1915.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1916.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1917.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1918.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1919.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1920.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1921.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1922.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1923.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1924.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1925.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1926.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1927.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1928.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1929.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1930.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1931.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1932.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1933.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1934.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1935.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1936.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1937.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1938.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1939.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1940.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1941.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1942.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1943.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1944.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1945.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1946.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1947.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1948.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1949.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1950.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1951.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1952.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1953.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1954.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1955.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1956.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1957.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1958.xml.gz\n",
      "1 ../../../data/vd1Min/20190322/ vd_value_1959.xml.gz\n"
     ]
    }
   ],
   "source": [
    "downnload1HourFiles2Mongo('vd', '20190322', 19, baseDir, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize #package for flattening json in pandas df\n",
    "\n",
    "def splitLane2DF(lanes):\n",
    "    tmpDF=json_normalize(data=lanes, record_path='cars', meta=['@vsrid', '@speed','@laneoccupy'])\n",
    "    records = tmpDF.to_dict('records')\n",
    "    return records\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "          \n",
    "def getAllFiles2Mongo(trType, day, baseDir, OneMinute=True):\n",
    "    if OneMinute:\n",
    "        directory=baseDir+trType+'1Min'+'/'+day+'/'\n",
    "        collect = db['vd1']\n",
    "    else:\n",
    "        directory=baseDir+trType+'/'+day+'/'\n",
    "    \n",
    "    files = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "    insertFiles2Mongo(files, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download5MinInsert(trType, day, baseDir):\n",
    "    downloadVD5MinDay(trType, day, baseDir)\n",
    "    getAllFiles2Mongo(trType, day, baseDir, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#days=['0405','0406','0407','0606','0607','0608'] #,'0624','0625','0626','0627','0628','0202','0203','0204','0205','0206','0207','0208','0209','0210']#\n",
    "#days=['1010','1011','1012','1013','0913','0914','0915']\n",
    "days=['0322','1210','1218']#,'0307']\n",
    "for d in days:\n",
    "    #downloadVD5MinDay('vd','2019'+d,baseDir)\n",
    "    getAllFiles2Mongo('vd','2019'+d,baseDir, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download1MinInsert(trType, day, baseDir):\n",
    "    downloadVD1MinDay(trType, day, baseDir)\n",
    "    getAllFiles2Mongo(trType, day, baseDir, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=['0322'] #,'1210','1218']#,'0307']\n",
    "for d in days:\n",
    "    download1MinInsert('vd','2019'+d,baseDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
